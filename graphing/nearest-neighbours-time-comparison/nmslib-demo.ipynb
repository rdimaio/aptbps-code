{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import multiprocessing\n",
    "#from bps import bps\n",
    "from sembps.bps import bps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.join('aptbps-code')\n",
    "LOGS_PATH = os.path.join(MAIN_PATH, 'logs')\n",
    "DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "\n",
    "train_path = os.path.join(DATA_PATH, 'train')\n",
    "hdf5_path = os.path.join(DATA_PATH, 'hdf5')\n",
    "no_unlabeled_h5_path = os.path.join(DATA_PATH, 'no_unlabeled_hdf5')\n",
    "hdf5_train_path = os.path.join(hdf5_path, 'train')\n",
    "encoded_hdf5_path = os.path.join(DATA_PATH, 'tree_encoded_hdf5')\n",
    "\n",
    "\n",
    "# All the clouds in the training dataset\n",
    "train_files = [\n",
    "    \"bildstein_station1_xyz_intensity_rgb\",\n",
    "    \"bildstein_station3_xyz_intensity_rgb\",\n",
    "    \"bildstein_station5_xyz_intensity_rgb\",\n",
    "    \"domfountain_station1_xyz_intensity_rgb\",\n",
    "    \"domfountain_station2_xyz_intensity_rgb\",\n",
    "    \"domfountain_station3_xyz_intensity_rgb\",\n",
    "    \"neugasse_station1_xyz_intensity_rgb\",\n",
    "    \"sg27_station1_intensity_rgb\",\n",
    "    \"sg27_station2_intensity_rgb\",\n",
    "    \"sg27_station4_intensity_rgb\",\n",
    "    \"sg27_station5_intensity_rgb\",\n",
    "    \"sg27_station9_intensity_rgb\",\n",
    "    \"sg28_station4_intensity_rgb\",\n",
    "    \"untermaederbrunnen_station1_xyz_intensity_rgb\",\n",
    "    \"untermaederbrunnen_station3_xyz_intensity_rgb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_orig_points = 2048\n",
    "n_bps_points = 512\n",
    "n_dims = 3\n",
    "radius = 1.5\n",
    "random_seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch of 100 point clouds to convert\n",
    "x = np.random.normal(size=[100, n_orig_points, 3])\n",
    "\n",
    "# optional point cloud normalization to fit a unit sphere\n",
    "x = bps.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clouds, n_points, n_dims = x.shape\n",
    "\n",
    "basis_set = bps.generate_random_basis(n_bps_points, n_dims=n_dims, radius=radius, random_seed=random_seed)\n",
    "\n",
    "n_bps_points = basis_set.shape[0]\n",
    "\n",
    "x_bps = np.zeros([n_clouds, n_bps_points])\n",
    "        \n",
    "fid_lst = range(0, x.shape[0])\n",
    "\n",
    "idx_bps = np.zeros([n_clouds, n_bps_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo (various cases with different tunings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random matrix to index\n",
    "data = np.random.randn(1000, 3).astype(np.float32)\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(x[0])\n",
    "index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "# query for the nearest neighbours of the first datapoint\n",
    "ids, distances = index.knnQuery(x[0], k=1)\n",
    "\n",
    "# get all nearest neighbours for all the datapoint\n",
    "# using a pool of 4 threads to compute\n",
    "neighbours = index.knnQueryBatch(basis_set, k=1, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.299919313052669\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    index = nmslib.init(method='hnsw', space='l2')\n",
    "    index.addDataPointBatch(x[fid])\n",
    "    index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "    neighbours = index.knnQueryBatch(basis_set, k=1, num_threads=4)\n",
    "    \n",
    "    for i in range (0, n_bps_points):\n",
    "        idx_bps[fid][i] = neighbours[i][0][0]\n",
    "        x_bps[fid][i] = neighbours[i][1][0]\n",
    "    \n",
    "    \n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1858., 1218.,   78., ..., 1625., 1697.,  368.],\n",
       "       [1308.,  586.,  324., ..., 1631.,  586., 1878.],\n",
       "       [ 343., 1079.,  263., ..., 1557., 1079., 1101.],\n",
       "       ...,\n",
       "       [ 733.,  162., 1322., ..., 1667.,  554., 1175.],\n",
       "       [1066., 1622., 1894., ..., 1034., 1622.,  498.],\n",
       "       [ 228., 1097., 1332., ...,  794., 1097.,  541.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2178341569378972\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "for fid in fid_lst:\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, leaf_size=16, algorithm='kd_tree').fit(x[fid])\n",
    "            fid_dist, npts_ix = nbrs.kneighbors(basis_set)\n",
    "            x_bps[fid] = fid_dist.squeeze()\n",
    "            idx_bps[fid] = npts_ix.squeeze()\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1858., 1218.,   78., ..., 1625., 1697.,  368.],\n",
       "       [1308.,  586.,  324., ..., 1631.,  586., 1878.],\n",
       "       [ 343., 1079.,  263., ..., 1557., 1079., 1101.],\n",
       "       ...,\n",
       "       [ 733.,  162., 1322., ..., 1667.,  554., 1175.],\n",
       "       [1066., 1622., 1894., ..., 1034., 1622.,  498.],\n",
       "       [ 228., 1097., 1332., ...,  794., 1097.,  541.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_bps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
