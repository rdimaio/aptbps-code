{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngtpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import multiprocessing\n",
    "from bps import bps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = os.path.join('aptbps-code')\n",
    "LOGS_PATH = os.path.join(MAIN_PATH, 'logs')\n",
    "DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "\n",
    "train_path = os.path.join(DATA_PATH, 'train')\n",
    "hdf5_path = os.path.join(DATA_PATH, 'hdf5')\n",
    "no_unlabeled_h5_path = os.path.join(DATA_PATH, 'no_unlabeled_hdf5')\n",
    "hdf5_train_path = os.path.join(hdf5_path, 'train')\n",
    "encoded_hdf5_path = os.path.join(DATA_PATH, 'tree_encoded_hdf5')\n",
    "\n",
    "\n",
    "# All the clouds in the training dataset\n",
    "train_files = [\n",
    "    \"bildstein_station1_xyz_intensity_rgb\",\n",
    "    \"bildstein_station3_xyz_intensity_rgb\",\n",
    "    \"bildstein_station5_xyz_intensity_rgb\",\n",
    "    \"domfountain_station1_xyz_intensity_rgb\",\n",
    "    \"domfountain_station2_xyz_intensity_rgb\",\n",
    "    \"domfountain_station3_xyz_intensity_rgb\",\n",
    "    \"neugasse_station1_xyz_intensity_rgb\",\n",
    "    \"sg27_station1_intensity_rgb\",\n",
    "    \"sg27_station2_intensity_rgb\",\n",
    "    \"sg27_station4_intensity_rgb\",\n",
    "    \"sg27_station5_intensity_rgb\",\n",
    "    \"sg27_station9_intensity_rgb\",\n",
    "    \"sg28_station4_intensity_rgb\",\n",
    "    \"untermaederbrunnen_station1_xyz_intensity_rgb\",\n",
    "    \"untermaederbrunnen_station3_xyz_intensity_rgb\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_orig_points = 2048\n",
    "n_bps_points = 512\n",
    "n_dims = 3\n",
    "radius = 1.5\n",
    "random_seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch of 100 point clouds to convert\n",
    "x = np.random.normal(size=[100, n_orig_points, 3])\n",
    "\n",
    "# optional point cloud normalization to fit a unit sphere\n",
    "x = bps.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clouds, n_points, n_dims = x.shape\n",
    "\n",
    "basis_set = bps.generate_random_basis(n_bps_points, n_dims=n_dims, radius=radius, random_seed=random_seed)\n",
    "\n",
    "n_bps_points = basis_set.shape[0]\n",
    "\n",
    "x_bps = np.zeros([n_clouds, n_bps_points])\n",
    "        \n",
    "fid_lst = range(0, x.shape[0])\n",
    "\n",
    "idx_bps = np.zeros([n_clouds, n_bps_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo (various cases with different tunings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6273797820322216\n"
     ]
    }
   ],
   "source": [
    "import ngtpy\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for fid in fid_lst: # this is jut an id\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "    \n",
    "    ngtpy.create(b\"tmp\", n_dims)\n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4736870580818504\n"
     ]
    }
   ],
   "source": [
    "import ngtpy\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "    \n",
    "    ngtpy.create(b\"tmp\", n_dims, distance_type='E')\n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    \n",
    "    # removing index.save speeds things up.\n",
    "    #index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it's faster when you don't save the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.475449724122882\n"
     ]
    }
   ],
   "source": [
    "import ngtpy\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "\n",
    "    ngtpy.create(b\"tmp\", n_dims)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    \n",
    "    # removing index.save speeds things up.\n",
    "    #index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't remove create, it's needed by the index.\n",
    "it only works if the folder already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.384827909991145\n"
     ]
    }
   ],
   "source": [
    "import ngtpy\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "\n",
    "    Removing create?\n",
    "    ngtpy.create(b\"tmp\", n_dims)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "\n",
    "    # removing index.save speeds things up.\n",
    "    #index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        # epsilon to 0.01\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, epsilon=0.01, with_distance=True)\n",
    "        print\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting epsilon to =0.01 seems to gain 0.1 s, while not losing any accuracy in neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3932263520546257\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "    \n",
    "    ngtpy.create(b\"tmp\", n_dims)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    index.set(num_of_search_objects=1, search_radius=3)\n",
    "\n",
    "    # removing index.save speeds things up.\n",
    "    #index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, epsilon=0.01, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using set doesn't seem to affect speed.\n",
    "PS i'm talking about the code above this text cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8678562201093882\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "    \n",
    "    # edge_size_for_creation greatly speeds up, search not as much\n",
    "    ngtpy.create(b\"tmp\", n_dims, edge_size_for_creation=2, edge_size_for_search=n_bps_points)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, epsilon=0.01, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# edge_size_for_creation, the lower it is the best speed, but lower accuracy.\n",
    "edge_size_for_search doesn't have much impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.885589514160529\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    objects = []\n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        objects.append(in_point)\n",
    "    \n",
    "    # edge_size_for_creation greatly speeds up, search not as much\n",
    "    ngtpy.create(b\"tmp\", n_dims, edge_size_for_creation=2, edge_size_for_search=n_bps_points)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(objects)\n",
    "    # no need to build index cause you're doing batch_insert\n",
    "    \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, epsilon=0.01, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.683734456077218\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    \n",
    "    # edge_size_for_creation greatly speeds up, search not as much\n",
    "    ngtpy.create(b\"tmp\", n_dims, edge_size_for_creation=2, edge_size_for_search=n_bps_points)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.batch_insert(x[fid])\n",
    "    \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, epsilon=0.01, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using batch_insert speeds up even more! use it like above, x[fid]. because fid is an id, not a cloud. so you index the input with fid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60961175, 1.0480746 , 1.164204  , ..., 0.07114316, 0.73357695,\n",
       "        0.50611889],\n",
       "       [0.28572312, 1.39232194, 0.94133115, ..., 0.22025135, 1.05862832,\n",
       "        0.63998073],\n",
       "       [0.35387206, 1.66672719, 1.48668611, ..., 0.22053802, 0.99216115,\n",
       "        0.45862544],\n",
       "       ...,\n",
       "       [0.45049804, 1.35216272, 0.62350333, ..., 0.23006508, 0.98464221,\n",
       "        0.854164  ],\n",
       "       [0.28062221, 0.77431917, 0.85941988, ..., 0.06398611, 0.56396478,\n",
       "        0.4961012 ],\n",
       "       [0.18557243, 1.08537304, 1.21393836, ..., 0.24177101, 0.85907215,\n",
       "        1.18087435]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are high distances, but it's due to edge_size_for_creation\n",
    "x_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimension experiment\n",
    "in the cell below, i will try making the index n_bps_points-dimensoinal (e.g. 512) and computing an entire basis point cloud against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09123187907971442\n",
      "[(0, 16.179702758789062)]\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "#print(x[0].shape)\n",
    "#\n",
    "#ngtpy.create(b\"tmp\", n_orig_points, edge_size_for_creation=2, edge_size_for_search=n_bps_points)\n",
    "#index = ngtpy.Index(b\"tmp\")\n",
    "#index.insert(x[0])\n",
    "\n",
    "for fid in fid_lst:\n",
    "    \n",
    "    # edge_size_for_creation greatly speeds up, search not as much\n",
    "    ngtpy.create(b\"tmp\", n_bps_points, edge_size_for_creation=2, edge_size_for_search=n_bps_points)\n",
    "    \n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    index.insert(x[fid])\n",
    "    index.build_index()\n",
    "    #index.batch_insert(objects)\n",
    "    # no need to build index cause you're doing batch_insert\n",
    "    \n",
    "    result = index.search(query=basis_set, size=1, epsilon=0.01, with_distance=True)\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doesn't really work.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60961175, 1.0480746 , 1.164204  , ..., 0.07114316, 0.73357695,\n",
       "        0.50611889],\n",
       "       [0.55201781, 0.70541543, 1.11996424, ..., 0.09831072, 0.62443298,\n",
       "        0.49821979],\n",
       "       [0.52505952, 0.89018458, 1.15248621, ..., 0.15370691, 0.63809961,\n",
       "        0.38013577],\n",
       "       ...,\n",
       "       [0.09815174, 1.13132966, 1.53206575, ..., 0.0105461 , 0.49830732,\n",
       "        0.55856138],\n",
       "       [0.09815174, 1.13132966, 1.53206575, ..., 0.0105461 , 0.46047688,\n",
       "        0.55856138],\n",
       "       [0.09815174, 1.13132966, 1.62510908, ..., 0.0105461 , 0.50163823,\n",
       "        0.14785343]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.993341371882707\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    ngtpy.create(\"anng\", n_dims)\n",
    "    index = ngtpy.Index(\"anng\")\n",
    "    \n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        index.insert(in_point)\n",
    "    \n",
    "    # this coud be useful for inserting everything at once\n",
    "    #index.batch_insert(objects)\n",
    "    index.build_index()\n",
    "    index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous two cells, you can see that index.insert(in_point) in the loop is slower than batch_insert in the cell before that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.81735324091278\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for fid in fid_lst:\n",
    "    ngtpy.create(b\"tmp\", n_dims)\n",
    "    index = ngtpy.Index(b\"tmp\")\n",
    "    \n",
    "    # Populate the list with input cloud\n",
    "    for in_point in x[fid]:\n",
    "        index.insert(in_point)\n",
    "    \n",
    "    # this coud be useful for inserting everything at once\n",
    "    #index.batch_insert(objects)\n",
    "    index.build_index()\n",
    "    #index.save()\n",
    "        \n",
    "    # Find nn for each point in basis point cloud\n",
    "    for b_idx, b_point in enumerate(basis_set):\n",
    "        result = index.search(query=[b_point[0], b_point[1], b_point[2]], size=1, with_distance=True)\n",
    "        idx_bps[fid][b_idx] = result[0][0]\n",
    "        x_bps[fid][b_idx] = result[0][1]\n",
    "\n",
    "    \n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 109.,  641.,  919., ..., 2029., 1131., 2022.],\n",
       "       [  64.,  435., 1086., ...,  774.,  228., 1390.],\n",
       "       [ 342.,   47.,  915., ..., 2004.,   47., 1127.],\n",
       "       ...,\n",
       "       [ 320., 1298.,  423., ..., 1220., 1506.,  850.],\n",
       "       [ 455., 1535., 1610., ..., 1101., 1535.,  694.],\n",
       "       [2012.,  766., 1993., ...,  107., 1755., 1316.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21903353603556752\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "for fid in fid_lst:\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, leaf_size=16, algorithm='kd_tree').fit(x[fid])\n",
    "            fid_dist, npts_ix = nbrs.kneighbors(basis_set)\n",
    "            x_bps[fid] = fid_dist.squeeze()\n",
    "            idx_bps[fid] = npts_ix.squeeze()\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
